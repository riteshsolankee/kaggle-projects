---
title: "InitialDataExploration"
author: "Ritesh Kumar"
date: "7/20/2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Introduction

 Exploratory Data Analysis for the [Personalized Medicine: Redefining Cancer Treatment](https://www.kaggle.com/c/msk-redefining-cancer-treatment) challenge. 

The goal of this project is to classify genetic mutations that contribute to cancer tumor growth ("drivers") in the presence of mutations that don't affect the tumors ("passengers").

The [data](https://www.kaggle.com/c/msk-redefining-cancer-treatment/data) comes in 4 different files. Two csv files and two text files:

- *training/test variants:* These are csv catalogues of the gene mutations together with the target value *Class*, which is the (manually) classified assessment of the mutation. The feature variables are *Gene*, the specific gene where the mutation took place, and *Variation*, the nature of the mutation. The test data of course doesn't have the *Class* values. This is what we have to predict. These two files each are linked through an *ID* variable to another file each, namely:

- *training/test text:* Those contain an extensive description of the evidence that was used (by experts) to manually label the mutation classes.

The data in the text column will be promarily used to build hte model for classification.

## Deleting all variables
```{r clear workspace}
rm(list=ls())
gc()
```

## Load libraries and data files

```{r, message = FALSE}
# visualization
library('ggplot2') 
library('ggthemes') 
library('scales') 
library('grid') 
library('gridExtra')
library('corrplot') 
library('ggfortify') 
library('ggraph') 
library('igraph')
library('ggbeeswarm') # plotting distrbution 
# data manipulation
library('dplyr') 
library('readr') # data input
library('tibble') # data wrangling
library('tidyr') # data wrangling
library('data.table')
# string manipulation
library('stringr') 
# factor manipulation
library('forcats') 
# text mining
library('tidytext') 
library('SnowballC') 
library('wordcloud') 
library('wordcloud2') 
library('tm')
library('RWeka')
options(mc.cores=1)
```

## Loading the datafiles
```{r}
# Load CSV files
cat("Read data")
train_text <- do.call(rbind,strsplit(readLines(unz("data/training_text.zip", "training_text")),'||',fixed=T))
train_text <- as.data.table(train_text)
train_text <- train_text[-1,]
colnames(train_text) <- c("ID", "Text")
train_text$ID <- as.numeric(train_text$ID)
train_txt <-
  train_text %>%
  select(ID, Text)

test_text <- do.call(rbind,strsplit(readLines(unz('data/test_text.zip','test_text')),'||',fixed=T))
test_text <- as.data.table(test_text)
test_text <- test_text[-1,]
colnames(test_text) <- c("ID", "Text")
test_text$ID <- as.numeric(test_text$ID)
test_txt <-
  test_text %>%
  select(ID, Text)

train <- fread("data/training_variants", sep=",", stringsAsFactors = T)
test <- fread("data/test_variants", sep=",", stringsAsFactors = T)
train <- merge(train,train_text,by="ID")
test <- merge(test,test_text,by="ID")
#rm(test_text,train_text);gc()

test$Class <- -1
data <- rbind(train,test)
#rm(train,test);gc()

```


```{r}
str(train)
str(test)
```

```{r}
nrow(train)
nrow(test)
```

```{r}
sum(is.na(train))
sum(is.na(test))
```

```{r}
train %>%
  group_by(Gene) %>%
  summarise(ct = n()) %>%
  arrange(desc(ct))

test %>%
  group_by(Gene) %>%
  summarise(ct = n()) %>%
  arrange(desc(ct))

train %>%
  group_by(Variation) %>%
  summarise(ct = n()) %>%
  arrange(desc(ct))

test %>%
  group_by(Variation) %>%
  summarise(ct = n()) %>%
  arrange(desc(ct))
```

We find:

- There are 3321 different *IDs* in the training set containing 264 different *Gene* expressions with 2996 different *Variations*. There are 9 different *Classes* indicated by integer levels.

- The *Gene* and *Variation* features contain character strings of various lengths.

- There is 70\% more test data than train data. The data description tells us that "Some of the test data is machine-generated to prevent hand labeling.", which should explain this otherwise curious imbalance.

- There are no missing values in the variants data.

- The most frequent *Genes* in the train vs test data are complete different. In addition, the test data seems to contain significantly more different *Genes* and fewer high-frequency *Genes* than the train data. To some extent, this might be an effect of the added machine-generate entries in the test data (by adding many different random levels). Thereby, the difference in frequency might mirror the true fraction of effective test data over train data.

- In contrast, the most frequent *Variations* in train vs test are largely identical; although, again, the corresponding frequencies are lower in the test data.


## Individual feature visualisations

This is the frequency distribution of the most frequent *Gene* values:

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 1", out.width="100%"}
top_gene <- train %>%
  group_by(Gene, Class) %>%
  summarise(ct = n()) %>%
  filter(ct > 20)

# top_gene %>%
#   ggplot(aes(reorder(Gene, -ct, FUN = min), ct)) +
#   geom_point(size = 4) +
#   labs(x = "Gene", y = "Frequency") +
#   coord_flip()

ggplot(
    top_gene,
    aes(x = reorder(Gene, -ct, FUN = min), y = ct, fill= factor(Class), size = ct)) +
  geom_point(shape = 21) +
  labs(x = "Gene", y = "Frequency") +
  coord_flip()
```

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 2", out.width="100%"}
# Stacked bar chat w.r.t genes
ggplot(
  data = top_gene,
  aes(x = reorder(Class, -ct, FUN = min), y = ct, fill = Gene)) +
  geom_bar(stat = "identity") + coord_flip() +
  theme(legend.position="bottom")
 
# Stacked bar chat w.r.t classed
# ggplot(
#   data = top_gene,
#   aes(x = reorder(Gene, -ct, FUN = min), y = ct, fill = Class)) +
#   geom_bar(stat = "identity") + coord_flip()
```

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 2", out.width="100%"}
top_gene_test <- test %>%
  group_by(Gene) %>%
  summarise(ct = n()) %>%
  filter(ct > 40)

top_gene_test %>%
  ggplot(aes(reorder(Gene, -ct, FUN = min), ct)) +
  geom_point(size = 4) +
  labs(x = "Gene", y = "Frequency") +
  coord_flip()
```

We find:

- A relatively small group of *Gene* levels make up a sizeable part of the feature values in both train and test data.

- The test data has fewer high-frequency *Genes*.

These are the most frequent *Variations* in the train (blue) vs test (red) data; confirming what we already saw by comparing the table data:

```{r  fig.align = 'default', message = FALSE, warning = FALSE, fig.cap ="Fig. 3", out.width="100%"}
foo <- train %>% mutate(set = factor("train")) %>% select(-Class, -ID)
bar <- test %>% mutate(set = factor("test")) %>% select(-ID)

foo <- full_join(foo, bar)

foo %>%
  group_by(Variation, set) %>%
  summarise(ct = n()) %>%
  filter(ct > 3) %>%
  ggplot(aes(reorder(Variation, -ct, FUN = median), ct, colour = set)) +
  geom_point(size = 4) +
  coord_cartesian(ylim = c(0, 100)) +
  labs(x = "Variation", y = "Frequency")
```

Here we see how the *Class* target is distributed in the train data:

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 4", out.width="100%"}
train %>%
  group_by(Class) %>%
  summarise(ct = n())  %>%
  arrange(desc(ct)) %>%
  ggplot(aes(x=reorder(Class, -ct), y=ct, fill=ct)) +
  geom_bar(stat = 'identity') +
  ggtitle("Train - Class target distribution\n", subtitle="Classes Vs  Count") + 
  xlab("\n Class") + 
  ylab("\n Count") 



```

We find:

- *Class* levels 3, 8, and 9 are notably under-represented

- Levels 5 and 6 are of comparable, medium-low frequency

- Levels 1, 2, and 4 are of comparable, medium-high frequency

- Level 7 is clearly the most frequent one


## Feature interactions

Now we want to examine how the features interact with each other and with the target *Class* variable.

### *Gene* vs *Class*

First, we will look at the frequency distribution of the overall most frequent *Genes* for the different *Classes*. Note the logarithmic frequency scale.


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 5", out.width="100%"}

train %>%
  group_by(Gene, Class) %>%
  summarise(ct = n())  %>%
  arrange(desc(ct)) %>%
  group_by(Class) %>%
  slice(1:5) %>% 
  ggplot(aes(x = reorder(Gene,-ct), y = ct, fill=ct)) + 
  geom_bar(stat = 'identity') + 
  theme_light() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Top 5 Genes Count", subtitle="Classes Vs Gene Count") + 
  xlab("\n Top-5 - Genes") + 
  ylab("\n Genes Count") +
  facet_wrap(~Class, ncol = 5, scales = "free")

```


```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 6", out.width="100%"}
train %>%
  filter(Gene %in% str_c(top_gene$Gene)) %>%
  group_by(Gene, Class) %>%
  summarise(ct = n())  %>%
  arrange(desc(ct)) %>%
  group_by(Class) %>%
  ggplot( 
  aes(x = factor(Class), y = ct, fill=ct)) + 
  geom_bar(stat = 'identity') + 
  theme_light() +
  scale_y_log10() +
  #theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  ggtitle("Genes Count against class ", subtitle="Gene Count Vs Classes") + 
  xlab("\n Genes") + 
  ylab("\n Class Count") +
  facet_wrap(~Gene)
```

We see immediately that there are significant differences:

- Some *Genes*, like "PTEN", are predominatly present in a single *Class* (here: 4).

- Other *Genes*, like "TP53", are mainly shared between 2 classes (here: 1 and 4).

- *Classes* 8 and 9 contain none of the most frequent *Genes*.

Here's what it looks like for the *Classes* sorted by *Genes* (again log counts):

```{r fig.align = 'default', warning = FALSE, fig.cap ="Fig. 6", out.width="100%"}
# xx <- train %>%
#   filter(Gene %in% str_c(top_gene$Gene))
# 
# train %>%
#   filter(Gene %in% str_c(top_gene$Gene)) %>%
#   ggplot(aes(Class)) +
#   geom_bar() +
#   scale_y_log10() +
#   facet_wrap(~ Gene)
```

This representation underlines our findings about the similar/dominating *Genes* in different *Classes*.


### *Gene* vs *Variation*

Next, we are somewhat repurposing a count plot to visualise how the *Variations* are distributed for the most frequent *Genes*. Since there are so many different variations we drop the y-axis labels and merely illustrate how many *Gene* - *Variation* combinations exist in the data.

First the training data:

```{r split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 7", out.width="100%"}
foo <- train %>%
  filter(Gene %in% str_c(top_gene$Gene)) %>%
  group_by(Gene, Variation) %>%
  summarise(ct = n())

y_labels <- str_sub(foo$Variation, start = 1, end = 5)
  
foo %>%
  ggplot(aes(reorder(Gene, ct, FUN = median), reorder(Variation, ct, FUN = median))) +
  geom_count() +
  labs(x = "Gene", y = "Variation") +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7),
        axis.ticks = element_blank(), axis.text.y = element_blank(),
        legend.position = "none")
```

Then the test data:

```{r split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 8", out.width="100%"}
foo <- test %>%
  filter(Gene %in% str_c(top_gene$Gene)) %>%
  group_by(Gene, Variation) %>%
  summarise(ct = n())

y_labels <- str_sub(foo$Variation, start = 1, end = 5)
  
foo %>%
  ggplot(aes(reorder(Gene, ct, FUN = median), reorder(Variation, ct, FUN = median))) +
  geom_count() +
  labs(x = "Gene", y = "Variation") +
  theme(axis.text.x  = element_text(angle=90, vjust=0.5, size=7),
        axis.ticks = element_blank(), axis.text.y = element_blank(),
        legend.position = "none")
```

Once more, the two data sets are rather heterogeneous in this view.


# The text files



## Feature Engineering

### Text length - txt\_len

```{r message = FALSE}
train_txt <- train_txt %>%
  mutate(txt_len = str_length(Text),
         set = "train")

test_txt <- test_txt %>%
  mutate(txt_len = str_length(Text),
         set = "test")

combine_txt <- full_join(train_txt,test_txt)
```

Now, examining the distribution of the length of the text features. Validate id the length of a paper is related to the classification outcome; i.e for example, check if the classifications require only a single paper or it's necessary to check multiple ones. 

First, here is the overall distribution of the text entry lengths in train vs test:

```{r split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 9", out.width="100%"}
combine_txt %>%
  ggplot(aes(txt_len, fill = set)) +
  geom_density(alpha = 0.5, bw = 5e3) +
  #geom_histogram(bins = 200) +
  labs(x = "Length of text entry")
```

The difference in distribution shape might again be due to the machine-generated entries that have been added to the test sample.

Now, let's see whether this distribution changes for the different target *Classes*. First, a facet wrap comparison:

```{r split=FALSE, fig.align = 'default', warning = FALSE, fig.cap ="Fig. 10", out.width="100%"}
train.txt <- train_txt %>%
  select(ID, txt_len)
tain.class <- train %>%
  select(ID, Class)

options(scipen=999)

full_join(train.txt, tain.class, by = "ID") %>%
  ggplot(aes(x = factor(Class), y = txt_len)) +
  geom_violin(aes(fill = factor(Class))) +
  #geom_beeswarm(aes(color = factor(Class)),alpha=.25) +
  geom_jitter(aes(color = factor(Class)) ,position=position_jitter(width=0.2), alpha=0.25) +
  theme(legend.position = "bottom", legend.direction = "horizontal") 
  




```

We find:

- There appear to be significant differences in the shape and median of the test length distributions. *Classes* 8 and 9 require on average more text, whereas *Class* 3 has the shortest/fewest papers associated with it.

- For what it's worth, it is tempting to speculate that the apparent multiple peaks in the text length distributions of the individual *Classes* could correspond to the number of papers that make up the clinical evidence.


### Missing text values

In the kaggle discussion it was [pointed out](https://www.kaggle.com/c/msk-redefining-cancer-treatment/discussion/35621) that a few observations have a "null " entry in their *text* features. Using our *txt\_len* feature we can confirm this finding and easily show that there are no other *text* values with less than 100 characters (just in case a different Null indicator would have been used):

```{r}
combine_txt %>%
  filter(txt_len < 100)
```


### Keyword frequency 



## First steps into text analysis with tidytext


```{r}
data("stop_words")
my_stopwords <- data_frame(word = c(as.character(1:100),
                                    "fig", "figure", "et", "al", "table",
                                    "data", "analysis", "analyze", "study",
                                    "method", "result", "conclusion", "author",
                                    "find", "found", "show", "perform",
                                    "demonstrate", "evaluate", "discuss"))


```

For a first overview, we have a look at the overall most popular words and their frequencies. This is our first serious application of tidyverse and ggplot2 tools to text data:


By and large, those are words that we would expect to find in a publication on cancer research and genetics. You will notice that for instance the top 4 words are essentially 2 variants of two basic words each. For our purposes these word variants are likely to obfuscate the signal we are interested in. We can reduce them to their basic meaning, their *word stem*, using a stemming tool.

As far as I can see, tidytext has currently no native stemming function. Therefore, we will use the "SnowballC" package and its "wordStem" tool:




```{r}

# Basic text features
cat("Basic text features")
getDocumentTermMatrices <- function (text.value){
  
  corpus <- Corpus(VectorSource(gsub("[^A-Za-z]", " ", text.value)))
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, removeWords, stopwords("english"))
  corpus <- tm_map(corpus, stemDocument, language="english")
  corpus <- tm_map(corpus, removeNumbers)

  text.dtm <- DocumentTermMatrix(corpus)
  text.tdm <- TermDocumentMatrix(corpus)
  list(CORPUS = corpus,  DTM = text.dtm, TDM = text.tdm)
}


```

```{r}

getFrequentWordDataFrame <- function(word.corpus, dtm, max.word.freq){
  freq.words <- findFreqTerms(dtm, max.word.freq)

  freq.words.tdm <- 
    TermDocumentMatrix(word.corpus, control = list(dictionary = freq.words))

  freq.words.tdm.df <- as.data.frame(rowSums(as.matrix(freq.words.tdm)))
  names(freq.words.tdm.df) <- 'count'
  freq.words.tdm.df$words <- rownames(freq.words.tdm.df)
  freq.words.tdm.df
}
```


```{r}
docs.train <- getDocumentTermMatrices(train$Text)
getFrequentWordDataFrame(docs.train$CORPUS, docs.train$DTM, 10000) %>%
  arrange(-count) %>%
  head(40) %>%
  ggplot(aes(x= reorder(words, count), y = count)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r}
docs.test <- getDocumentTermMatrices(test$Text)
getFrequentWordDataFrame(docs.test$CORPUS, docs.test$DTM, 10000)  %>%
  arrange(-count) %>%
  head(40) %>%
  ggplot(aes(x= reorder(words, count), y = count)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()
```

```{r}

docs.combine <- getDocumentTermMatrices(data$Text)
getFrequentWordDataFrame(docs.combine$CORPUS, docs.combine$DTM, 10000)  %>%
  arrange(-count) %>%
  head(40) %>%
  ggplot(aes(x= reorder(words, count), y = count)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

```

## Wordcloud - comparision & commonality

```{r, message=FALSE, warning=FALSE}
str(train)
dfForEachClass <- function(train.text){
  class1.text <- 
    train.text %>%
    filter(Class == 1) %>%
    select(Text)
  class2.text <- 
    train.text %>%
    filter(Class == 2) %>%
    select(Text)
  class3.text <- 
    train.text %>%
    filter(Class == 3) %>%
    select(Text)
  class4.text <- 
    train.text %>%
    filter(Class == 4) %>%
    select(Text)
  class5.text <- 
    train.text %>%
    filter(Class == 5) %>%
    select(Text)
  class6.text <- 
    train.text %>%
    filter(Class == 6) %>%
    select(Text)
  class7.text <- 
    train.text %>%
    filter(Class == 7) %>%
    select(Text)
  class8.text <- 
    train.text %>%
    filter(Class == 8) %>%
    select(Text)
  class9.text <- 
    train.text %>%
    filter(Class == 9) %>%
    select(Text)
  list(C1 = class1.text, C2 = class2.text, C3 = class3.text,
       C4 = class4.text, C5 = class5.text, C6 = class6.text,
       C7 = class7.text, C8 = class8.text, C9 = class9.text)
}
class.txt.list <- dfForEachClass(train)

df.list <- list()
index <- 1
# doc.list <- getDocumentTermMatrices(class.txt.list$C1)
# df.list <- c(df.list, getFrequentWordDataFrame(doc.list$CORPUS, doc.list$DTM, 1000))
for(class.txt in class.txt.list){
  doc.list <- getDocumentTermMatrices(class.txt)
  df <- getFrequentWordDataFrame(doc.list$CORPUS, doc.list$DTM, 1000)
  colnames(df)[which(names(df) == "count")] <- paste("Class -", index, sep="")
  df.list[[index]] <- df
    
  index <- index + 1
}

final.df <- Reduce(function(dtf1, dtf2) merge(dtf1, dtf2, by = "words", all = TRUE), df.list)
final.df[is.na(final.df)] <- 0
row.names(final.df ) <- final.df$words
final.matrix.all <- as.matrix(final.df[,c(-1)]) 
```

### Comparing words frequency of all classes 

```{r, message=FALSE, warning=FALSE}
comparison.cloud(final.matrix.all, title.size = 1.5, max.words=400, random.order = FALSE, scale = c(2,.8), rot.per=10) 

```

### Common words among all classes

```{r}
commonality.cloud(final.matrix.all, max.words=200, random.order=FALSE, scale=c(5, 2),colors = brewer.pal(4, "Dark2"))
```



### Class - 1

```{r}
par(mfrow=c(1,2))
wordcloud2(final.df[,c(1,2)])
```

### Class - 2

```{r}
wordcloud2(final.df[,c(1,3)])
```

### Class - 3

```{r }
wordcloud2(final.df[,c(1,4)])
```

### Class - 4

```{r }
wordcloud2(final.df[,c(1,5)])
```

### Class - 5

```{r }
wordcloud2(final.df[,c(1,6)])
```

### Class - 6

```{r }
wordcloud2(final.df[,c(1,7)])
```

### Class - 7

```{r }
wordcloud2(final.df[,c(1,8)])
```

### Class - 8

```{r }
wordcloud2(final.df[,c(1,9)])
```

### Class - 9

```{r }
wordcloud2(final.df[,c(1,10)])
```

## n-gram analysis
### Frequent words

```{r}
cat("bigram corpus creation")
corpus.ng <- VCorpus(VectorSource(gsub("[^A-Za-z0-9 ]", " ", train$Text)))
corpus.ng <- tm_map(corpus.ng, stripWhitespace)
corpus.ng <- tm_map(corpus.ng, content_transformer(tolower))
corpus.ng <- tm_map(corpus.ng, removePunctuation)
corpus.ng <- tm_map(corpus.ng, removeWords, stopwords("english"))
corpus.ng <- tm_map(corpus.ng, stemDocument, language="english")
corpus.ng <- tm_map(corpus.ng, removeNumbers)
#corpus.ng <- tm_map(corpus.ng, BigramTokenizer)
## bigram tokenizer
BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))
TrigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 3, max = 3))
#text.dtm.ng <- DocumentTermMatrix(corpus.ng, control = list(tokenize = BigramTokenizer))
```


### Bigram word frequency

```{r}
text.tdm.bigram <- TermDocumentMatrix(corpus.ng, control = list(tokenize = BigramTokenizer))
bi.terms <- findFreqTerms(text.tdm.bigram, 5000)
bigram <- text.tdm.bigram[bi.terms,] %>%
      as.matrix() %>%
      rowSums()  %>% 
      data.frame(Term = bi.terms, Frequency = .) %>%  
      arrange(desc(Frequency))
wordcloud2(bigram)
```

### Trigram word frequency

```{r}
text.tdm.trigram <- TermDocumentMatrix(corpus.ng, control = list(tokenize = TrigramTokenizer))
tri.terms <- findFreqTerms(text.tdm.trigram, 500)
trigram <- text.tdm.trigram[tri.terms,] %>%
      as.matrix() %>%
      rowSums()  %>% 
      data.frame(Term = tri.terms, Frequency = .) %>%  
      arrange(desc(Frequency))
wordcloud2(trigram)
```


## TF-IDF Analysis

```{r}

```

## Class wise word Network analysis

```{r}

```

